{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# need to reload kernel between runs of this\n",
    "os.chdir('genre_classification_289a/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from analysis_utils import find_available_mlp_models, get_model_f1s, get_model_loss_histories, abbrev_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available MLP Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': 'fma_medium', 'targets': ['subgenres'], 'layer': 7}\n",
      "{'dataset': 'fma_medium', 'targets': ['subgenres'], 'layer': 6}\n",
      "{'dataset': 'fma_medium', 'targets': ['subgenres'], 'layer': 5}\n",
      "{'dataset': 'fma_medium', 'targets': ['subgenres', 'mfcc', 'genre'], 'layer': 7}\n",
      "{'dataset': 'fma_medium', 'targets': ['subgenres', 'mfcc', 'genre'], 'layer': 6}\n",
      "{'dataset': 'fma_medium', 'targets': ['subgenres', 'mfcc', 'genre'], 'layer': 5}\n",
      "{'dataset': 'fma_medium', 'targets': ['subgenres', 'mfcc', 'genre'], 'layer': 4}\n"
     ]
    }
   ],
   "source": [
    "# set possible file attrs\n",
    "dataset_name = \"fma_medium\"\n",
    "possible_targets = [\"subgenres\", \"mfcc\", \"genre\"]\n",
    "possible_layers = [7,6,5,4]\n",
    "save_plots_path = os.path.join(os.path.curdir, \"../models/analysis-plots/\")\n",
    "\n",
    "mlp_models = find_available_mlp_models(dataset_name, possible_targets, possible_layers)\n",
    "for model in mlp_models:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of F1 (micro) Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8602 <= layer: 7, targets: ['subgenres']\n",
      "0.8802 <= layer: 6, targets: ['subgenres']\n",
      "0.7275 <= layer: 5, targets: ['subgenres']\n",
      "0.9747 <= layer: 7, targets: ['subgenres', 'mfcc', 'genre']\n",
      "0.9611 <= layer: 6, targets: ['subgenres', 'mfcc', 'genre']\n",
      "0.7905 <= layer: 5, targets: ['subgenres', 'mfcc', 'genre']\n",
      "0.6721 <= layer: 4, targets: ['subgenres', 'mfcc', 'genre']\n"
     ]
    }
   ],
   "source": [
    "mlp_f1s = get_model_f1s(mlp_models)\n",
    "\n",
    "for idx, f1 in enumerate(mlp_f1s):\n",
    "    print(f\"{f1.round(4)} <= layer: {mlp_models[idx]['layer']}, targets: {mlp_models[idx]['targets']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots of Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-5f96b89c73be>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-5f96b89c73be>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    plt.figure()\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "mlp_loss_histories = get_model_loss_histories(mlp_models)\n",
    "batch_set_size = 30\n",
    "\n",
    "# regular plot\n",
    "plt.figure()\n",
    "plt.title(\"MLP Training Loss\")\n",
    "for idx, mlp_loss_history in enumerate(mlp_loss_histories):\n",
    "    label = f\"{abbrev_targets(mlp_models[idx]['targets'])}:{mlp_models[idx]['layer']}\"\n",
    "    plt.plot((np.arange(len(mlp_loss_history))+1)*batch_set_size, mlp_loss_history, label=label)\n",
    "plt.ylabel(\"30-Batch Average Loss\")\n",
    "plt.xlabel(\"Batches\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(save_plots_path, f\"MLP-training-losses.png\"))\n",
    "\n",
    "# smoother plot (average every 8 sets of 30 batch loss averages)\n",
    "plt.figure()\n",
    "plt.title(\"MLP Training Loss (Smooth)\")\n",
    "n_avg = 20 # num losses to average across\n",
    "\n",
    "# stack @Jaime\n",
    "def moving_average(a, n) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "for idx, mlp_loss_history in enumerate(mlp_loss_histories):\n",
    "    # V1 Smooth (batch average)\n",
    "#     losses = np.array(mlp_loss_history)\n",
    "#     nrows = int(losses.shape[0]/ncols)\n",
    "#     # truncate to be evenly divisble by `average_across`\n",
    "#     losses_truncated = losses[:ncols*nrows]\n",
    "#     # reshape to get rows of 8 loss samples\n",
    "#     losses_mat = losses_truncated.reshape(nrows, ncols)\n",
    "#     # average across each row (set of 30-batche loss averages)\n",
    "#     losses_avg = np.average(losses_mat, 1)\n",
    "#     label = f\"{abbrev_targets(mlp_models[idx]['targets'])}:{mlp_models[idx]['layer']}\"\n",
    "#     plt.plot((np.arange(len(losses_avg))+1)*batch_set_size*ncols, losses_avg, label=label)\n",
    "    # V2 Smooth (moving average, much better metric)\n",
    "    losses = np.array(mlp_loss_history)\n",
    "    losses_avg = moving_average(losses, n_avg)\n",
    "    label = f\"{abbrev_targets(mlp_models[idx]['targets'])}:{mlp_models[idx]['layer']}\"\n",
    "    plt.plot((np.arange(len(losses_avg))+1)*batch_set_size, losses_avg, label=label)\n",
    "plt.ylabel(f\"{n_avg}-Tap Moving Avg of 30-Batch Average of Loss\")\n",
    "plt.xlabel(\"Batches\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(save_plots_path, f\"MLP-training-losses-smooth-{n_avg}.png\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
