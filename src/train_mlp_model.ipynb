{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Training Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('genre_classification_289a/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from model import STN, MLP\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features import get_data_loaders, FramedFeatureDataset, FeatureDataset, DatasetSettings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP target always genre\n",
    "agfs = [] #'subgenre', 'mfcc'\n",
    "genre = True #False if not genre STN\n",
    "    \n",
    "#dataset\n",
    "dataset_name = 'fma_medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num genres:  16\n",
      "Rock                   6911\n",
      "Electronic             6110\n",
      "Experimental           2207\n",
      "Hip-Hop                2109\n",
      "Folk                   1477\n",
      "Instrumental           1280\n",
      "Pop                    1129\n",
      "International          1004\n",
      "Classical               598\n",
      "Old-Time / Historic     510\n",
      "Jazz                    380\n",
      "Country                 178\n",
      "Soul-RnB                154\n",
      "Spoken                  118\n",
      "Blues                    72\n",
      "Easy Listening           21\n",
      "Name: genre_top, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "settings = DatasetSettings(dataset_name, 'fma_metadata')\n",
    "dataset = FramedFeatureDataset(settings,  agfs=agfs, genre=genre)\n",
    "print(\"Num genres: \", settings.num_genres)\n",
    "print(settings.genre_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stn_path(dataset, target):\n",
    "    return '../models/DCNN_{}_{}'.format(dataset, target)\n",
    "\n",
    "# load STNs\n",
    "targets = ['mfcc', 'subgenres']#['subgenres', 'mfcc', 'genre']\n",
    "stns = [torch.load(get_stn_path(dataset_name, target)).to(device) for target in targets]\n",
    "stn_layer_dims = [None, 16, 32, 64, 64, 128, 256, 256]\n",
    "\n",
    "#which layer to extract features from\n",
    "layer = 7\n",
    "\n",
    "# setup MLP on GPU\n",
    "mlp_input_size = len(targets) * stn_layer_dims[layer]\n",
    "mlp_output_size = settings.num_genres\n",
    "mlp = MLP(mlp_input_size, mlp_output_size)\n",
    "mlp.to(device)\n",
    "mlp = nn.DataParallel(mlp)\n",
    "\n",
    "## Training Parameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mlp.parameters(), lr=0.001)\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "valid_split = 0.2\n",
    "\n",
    "trainloader, validloader = get_data_loaders(dataset, batch_size, valid_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def validate():\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for stn in stns:\n",
    "            stn.eval()\n",
    "        mlp.eval()\n",
    "                \n",
    "        all_pred = []\n",
    "        all_true = []\n",
    "        \n",
    "        for i, data in enumerate(validloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1]['genre'].to(device)\n",
    "            \n",
    "            out_intermediate = [stn.module.forward_intermediate(inputs, layer) for stn in stns]\n",
    "            input_mlp = torch.cat(out_intermediate, dim=1)\n",
    "            \n",
    "            out = mlp(input_mlp)\n",
    "            loss = F.cross_entropy(out, labels)\n",
    "            \n",
    "            all_pred.append(out.argmax(dim=1))\n",
    "            all_true.append(labels)\n",
    "            \n",
    "        all_pred = torch.cat(all_pred)\n",
    "        all_true = torch.cat(all_true)\n",
    "        \n",
    "        curr_f1 = f1_score(all_true.cpu(), all_pred.cpu(), average='micro')\n",
    "        return curr_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.48 Âµs\n",
      "Starting epoch 1\n",
      "[1,    30] loss: 1.668\n",
      "[1,    60] loss: 1.040\n",
      "[1,    90] loss: 0.973\n",
      "[1,   120] loss: 0.832\n",
      "[1,   150] loss: 0.844\n",
      "[1,   180] loss: 0.801\n",
      "[1,   210] loss: 0.728\n",
      "[1,   240] loss: 0.738\n",
      "[1,   270] loss: 0.749\n",
      "[1,   300] loss: 0.734\n",
      "[1,   330] loss: 0.721\n",
      "[1,   360] loss: 0.676\n",
      "[1,   390] loss: 0.596\n",
      "[1,   420] loss: 0.651\n",
      "[1,   450] loss: 0.694\n",
      "[1,   480] loss: 0.633\n",
      "[1,   510] loss: 0.632\n",
      "[1,   540] loss: 0.657\n",
      "[1,   570] loss: 0.655\n",
      "[1,   600] loss: 0.676\n",
      "[1,   630] loss: 0.656\n",
      "[1,   660] loss: 0.626\n",
      "[1,   690] loss: 0.627\n",
      "[1,   720] loss: 0.602\n"
     ]
    }
   ],
   "source": [
    "#Train it\n",
    "%time\n",
    "losses = []\n",
    "accs = []\n",
    "for stn in stns:\n",
    "    stn.eval()\n",
    "\n",
    "\n",
    "#f.write('Initial Validation F1: %.6f' % validate())\n",
    "\n",
    "mlp.train()\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    print('Starting epoch %d' % (epoch+1))\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data[0].to(device), data[1]['genre'].to(device)  #data[1]['{argument for agf being trained}']\n",
    "        \n",
    "        input_mlp = None\n",
    "        with torch.no_grad():\n",
    "            out_intermediates = [stn.module.forward_intermediate(inputs, layer) for stn in stns]\n",
    "            input_mlp = torch.cat(out_intermediates, dim=1)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = mlp(input_mlp)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 30 == 29:    # print every 30 mini-batches\n",
    "            avg_loss = running_loss / 30\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, avg_loss))\n",
    "            losses.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "final_f1 = validate()\n",
    "np.array(losses).tofile(f'logs/losses_MLP_{dataset_name}_stn_{\"_\".join(targets)}_layer_{layer}')\n",
    "np.array(final_f1).tofile(f'logs/final_MLP_{dataset_name}_stn_{\"_\".join(targets)}_layer_{layer}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = f'../models/MLP_{dataset_name}_stn_{\"_\".join(targets)}_layer_{layer}'\n",
    "torch.save(mlp, model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Eval Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = f'../models/MLP_{dataset_name}_stn_{\"_\".join(targets)}_layer_{layer}'\n",
    "mlp = torch.load(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load losses and final accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = np.fromfile(f'logs/losses_MLP_{dataset_name}_stn_{\"_\".join(targets)}_layer_{layer}')\n",
    "final_f1 = np.fromfile(f'logs/final_MLP_{dataset_name}_stn_{\"_\".join(targets)}_layer_{layer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Performance History\n",
    "* SGM layer 4: 0.67209446\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
