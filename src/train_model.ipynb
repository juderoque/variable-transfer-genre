{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('genre_classification_289a/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from model import STN, MLP\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pop              1000\n",
      "International    1000\n",
      "Instrumental     1000\n",
      "Folk             1000\n",
      "Rock              999\n",
      "Experimental      999\n",
      "Electronic        999\n",
      "Hip-Hop           997\n",
      "Name: genre_top, dtype: int64\n",
      "{'Pop': 0, 'International': 1, 'Instrumental': 2, 'Folk': 3, 'Rock': 4, 'Experimental': 5, 'Electronic': 6, 'Hip-Hop': 7}\n"
     ]
    }
   ],
   "source": [
    "from features import get_data_loaders, genre_counts, FramedFeatureDataset, FeatureDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_genres = len(genre_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STN targets\n",
    "agfs = []\n",
    "genre = True\n",
    "\n",
    "#dataset\n",
    "dataset_name = 'fma_small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stn = STN(len(genre_counts))\n",
    "stn.to(device)\n",
    "stn = nn.DataParallel(stn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training Parameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(stn.parameters(), lr=0.001)\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "valid_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FramedFeatureDataset(agfs=agfs, genre=genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, validloader = get_data_loaders(dataset, batch_size, valid_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def validate(stn, label_name):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        stn.eval()\n",
    "        \n",
    "        all_pred = []\n",
    "        all_true = []\n",
    "        \n",
    "        for i, data in enumerate(validloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1][label_name].to(device)\n",
    "            \n",
    "            out = stn(inputs)\n",
    "            loss = F.cross_entropy(out, labels)\n",
    "            \n",
    "            all_pred.append(out.argmax(dim=1))\n",
    "            all_true.append(labels)\n",
    "            \n",
    "        all_pred = torch.cat(all_pred)\n",
    "        all_true = torch.cat(all_true)\n",
    "        \n",
    "        curr_f1 = f1_score(all_true.cpu(), all_pred.cpu(), average='micro')\n",
    "        \n",
    "        print('Validation f1 score: {}'.format(curr_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "[1,    50] loss: 3.127\n",
      "[1,   100] loss: 2.726\n",
      "[1,   150] loss: 2.606\n",
      "[1,   200] loss: 2.527\n",
      "[1,   250] loss: 2.459\n",
      "[1,   300] loss: 2.350\n",
      "[1,   350] loss: 2.364\n",
      "[1,   400] loss: 2.305\n",
      "[1,   450] loss: 2.217\n",
      "[1,   500] loss: 2.240\n",
      "[1,   550] loss: 2.188\n",
      "[1,   600] loss: 2.243\n",
      "[1,   650] loss: 2.220\n",
      "[1,   700] loss: 2.179\n",
      "Starting epoch 2\n",
      "[2,    50] loss: 2.090\n",
      "[2,   100] loss: 2.071\n",
      "[2,   150] loss: 2.088\n",
      "[2,   200] loss: 2.020\n",
      "[2,   250] loss: 2.041\n",
      "[2,   300] loss: 2.024\n",
      "[2,   350] loss: 1.974\n",
      "[2,   400] loss: 2.039\n",
      "[2,   450] loss: 1.999\n",
      "[2,   500] loss: 1.987\n",
      "[2,   550] loss: 1.917\n",
      "[2,   600] loss: 1.976\n",
      "[2,   650] loss: 1.997\n",
      "[2,   700] loss: 1.866\n",
      "Starting epoch 3\n",
      "[3,    50] loss: 1.891\n",
      "[3,   100] loss: 1.842\n",
      "[3,   150] loss: 1.937\n",
      "[3,   200] loss: 1.826\n",
      "[3,   250] loss: 1.921\n",
      "[3,   300] loss: 1.831\n",
      "[3,   350] loss: 1.818\n",
      "[3,   400] loss: 1.844\n",
      "[3,   450] loss: 1.817\n",
      "[3,   500] loss: 1.808\n",
      "[3,   550] loss: 1.837\n",
      "[3,   600] loss: 1.796\n",
      "[3,   650] loss: 1.737\n",
      "[3,   700] loss: 1.723\n",
      "Starting epoch 4\n",
      "[4,    50] loss: 1.690\n",
      "[4,   100] loss: 1.731\n",
      "[4,   150] loss: 1.728\n",
      "[4,   200] loss: 1.667\n",
      "[4,   250] loss: 1.712\n",
      "[4,   300] loss: 1.662\n",
      "[4,   350] loss: 1.606\n",
      "[4,   400] loss: 1.724\n",
      "[4,   450] loss: 1.676\n",
      "[4,   500] loss: 1.687\n",
      "[4,   550] loss: 1.613\n",
      "[4,   600] loss: 1.626\n",
      "[4,   650] loss: 1.655\n",
      "[4,   700] loss: 1.623\n",
      "Starting epoch 5\n",
      "[5,    50] loss: 1.523\n",
      "[5,   100] loss: 1.449\n",
      "[5,   150] loss: 1.514\n",
      "[5,   200] loss: 1.482\n",
      "[5,   250] loss: 1.488\n",
      "[5,   300] loss: 1.547\n",
      "[5,   350] loss: 1.484\n",
      "[5,   400] loss: 1.536\n",
      "[5,   450] loss: 1.564\n",
      "[5,   500] loss: 1.427\n",
      "[5,   550] loss: 1.458\n",
      "[5,   600] loss: 1.453\n",
      "[5,   650] loss: 1.426\n",
      "[5,   700] loss: 1.497\n",
      "Validation f1 score: 0.624698418371906\n",
      "Starting epoch 6\n",
      "[6,    50] loss: 1.408\n",
      "[6,   100] loss: 1.278\n",
      "[6,   150] loss: 1.350\n",
      "[6,   200] loss: 1.272\n",
      "[6,   250] loss: 1.314\n",
      "[6,   300] loss: 1.288\n",
      "[6,   350] loss: 1.303\n",
      "[6,   400] loss: 1.347\n",
      "[6,   450] loss: 1.263\n",
      "[6,   500] loss: 1.302\n",
      "[6,   550] loss: 1.314\n",
      "[6,   600] loss: 1.267\n",
      "[6,   650] loss: 1.253\n",
      "[6,   700] loss: 1.315\n",
      "Starting epoch 7\n",
      "[7,    50] loss: 1.170\n",
      "[7,   100] loss: 1.061\n",
      "[7,   150] loss: 1.097\n",
      "[7,   200] loss: 1.140\n",
      "[7,   250] loss: 1.092\n",
      "[7,   300] loss: 1.167\n",
      "[7,   350] loss: 1.102\n",
      "[7,   400] loss: 1.129\n",
      "[7,   450] loss: 1.056\n",
      "[7,   500] loss: 1.168\n",
      "[7,   550] loss: 1.169\n",
      "[7,   600] loss: 1.065\n",
      "[7,   650] loss: 1.118\n",
      "[7,   700] loss: 1.102\n",
      "Starting epoch 8\n",
      "[8,    50] loss: 0.953\n",
      "[8,   100] loss: 0.929\n",
      "[8,   150] loss: 0.923\n",
      "[8,   200] loss: 0.849\n",
      "[8,   250] loss: 0.920\n",
      "[8,   300] loss: 0.948\n",
      "[8,   350] loss: 0.901\n",
      "[8,   400] loss: 0.918\n",
      "[8,   450] loss: 0.894\n",
      "[8,   500] loss: 0.971\n",
      "[8,   550] loss: 0.863\n",
      "[8,   600] loss: 0.892\n",
      "[8,   650] loss: 0.881\n",
      "[8,   700] loss: 0.832\n",
      "Starting epoch 9\n",
      "[9,    50] loss: 0.722\n",
      "[9,   100] loss: 0.726\n",
      "[9,   150] loss: 0.684\n",
      "[9,   200] loss: 0.757\n",
      "[9,   250] loss: 0.711\n",
      "[9,   300] loss: 0.728\n",
      "[9,   350] loss: 0.752\n",
      "[9,   400] loss: 0.722\n",
      "[9,   450] loss: 0.729\n",
      "[9,   500] loss: 0.748\n",
      "[9,   550] loss: 0.776\n",
      "[9,   600] loss: 0.748\n",
      "[9,   650] loss: 0.741\n",
      "[9,   700] loss: 0.736\n",
      "Starting epoch 10\n",
      "[10,    50] loss: 0.564\n",
      "[10,   100] loss: 0.614\n",
      "[10,   150] loss: 0.536\n",
      "[10,   200] loss: 0.592\n",
      "[10,   250] loss: 0.653\n",
      "[10,   300] loss: 0.631\n",
      "[10,   350] loss: 0.578\n",
      "[10,   400] loss: 0.596\n",
      "[10,   450] loss: 0.636\n",
      "[10,   500] loss: 0.587\n",
      "[10,   550] loss: 0.603\n",
      "[10,   600] loss: 0.592\n",
      "[10,   650] loss: 0.586\n",
      "[10,   700] loss: 0.612\n",
      "Validation f1 score: 0.8202126708962558\n",
      "Starting epoch 11\n",
      "[11,    50] loss: 0.442\n",
      "[11,   100] loss: 0.453\n",
      "[11,   150] loss: 0.449\n",
      "[11,   200] loss: 0.503\n",
      "[11,   250] loss: 0.475\n",
      "[11,   300] loss: 0.459\n",
      "[11,   350] loss: 0.542\n",
      "[11,   400] loss: 0.516\n",
      "[11,   450] loss: 0.509\n",
      "[11,   500] loss: 0.526\n",
      "[11,   550] loss: 0.499\n",
      "[11,   600] loss: 0.457\n",
      "[11,   650] loss: 0.446\n",
      "[11,   700] loss: 0.543\n",
      "Starting epoch 12\n",
      "[12,    50] loss: 0.359\n",
      "[12,   100] loss: 0.361\n",
      "[12,   150] loss: 0.377\n",
      "[12,   200] loss: 0.437\n",
      "[12,   250] loss: 0.433\n",
      "[12,   300] loss: 0.454\n",
      "[12,   350] loss: 0.364\n",
      "[12,   400] loss: 0.366\n",
      "[12,   450] loss: 0.441\n",
      "[12,   500] loss: 0.414\n",
      "[12,   550] loss: 0.452\n",
      "[12,   600] loss: 0.449\n",
      "[12,   650] loss: 0.426\n",
      "[12,   700] loss: 0.475\n",
      "Starting epoch 13\n",
      "[13,    50] loss: 0.273\n",
      "[13,   100] loss: 0.271\n",
      "[13,   150] loss: 0.279\n",
      "[13,   200] loss: 0.347\n",
      "[13,   250] loss: 0.342\n",
      "[13,   300] loss: 0.311\n",
      "[13,   350] loss: 0.341\n",
      "[13,   400] loss: 0.360\n",
      "[13,   450] loss: 0.354\n",
      "[13,   500] loss: 0.362\n",
      "[13,   550] loss: 0.365\n",
      "[13,   600] loss: 0.353\n",
      "[13,   650] loss: 0.359\n",
      "[13,   700] loss: 0.381\n",
      "Starting epoch 14\n",
      "[14,    50] loss: 0.276\n",
      "[14,   100] loss: 0.252\n",
      "[14,   150] loss: 0.216\n",
      "[14,   200] loss: 0.358\n",
      "[14,   250] loss: 0.284\n",
      "[14,   300] loss: 0.312\n",
      "[14,   350] loss: 0.333\n",
      "[14,   400] loss: 0.264\n",
      "[14,   450] loss: 0.295\n",
      "[14,   500] loss: 0.346\n",
      "[14,   550] loss: 0.353\n",
      "[14,   600] loss: 0.338\n",
      "[14,   650] loss: 0.367\n",
      "[14,   700] loss: 0.274\n",
      "Starting epoch 15\n",
      "[15,    50] loss: 0.192\n",
      "[15,   100] loss: 0.238\n",
      "[15,   150] loss: 0.236\n",
      "[15,   200] loss: 0.182\n",
      "[15,   250] loss: 0.219\n",
      "[15,   300] loss: 0.261\n",
      "[15,   350] loss: 0.305\n",
      "[15,   400] loss: 0.311\n",
      "[15,   450] loss: 0.283\n",
      "[15,   500] loss: 0.306\n",
      "[15,   550] loss: 0.282\n",
      "[15,   600] loss: 0.309\n",
      "[15,   650] loss: 0.299\n",
      "[15,   700] loss: 0.295\n",
      "Validation f1 score: 0.8564024662675365\n",
      "Starting epoch 16\n",
      "[16,    50] loss: 0.199\n",
      "[16,   100] loss: 0.208\n",
      "[16,   150] loss: 0.232\n",
      "[16,   200] loss: 0.196\n",
      "[16,   250] loss: 0.172\n",
      "[16,   300] loss: 0.232\n",
      "[16,   350] loss: 0.211\n",
      "[16,   400] loss: 0.218\n",
      "[16,   450] loss: 0.260\n",
      "[16,   500] loss: 0.313\n",
      "[16,   550] loss: 0.259\n",
      "[16,   600] loss: 0.290\n",
      "[16,   650] loss: 0.274\n",
      "[16,   700] loss: 0.316\n",
      "Starting epoch 17\n",
      "[17,    50] loss: 0.186\n",
      "[17,   100] loss: 0.191\n",
      "[17,   150] loss: 0.228\n",
      "[17,   200] loss: 0.234\n",
      "[17,   250] loss: 0.188\n",
      "[17,   300] loss: 0.187\n",
      "[17,   350] loss: 0.206\n",
      "[17,   400] loss: 0.240\n",
      "[17,   450] loss: 0.233\n",
      "[17,   500] loss: 0.201\n",
      "[17,   550] loss: 0.226\n",
      "[17,   600] loss: 0.225\n",
      "[17,   650] loss: 0.214\n",
      "[17,   700] loss: 0.245\n",
      "Starting epoch 18\n",
      "[18,    50] loss: 0.208\n",
      "[18,   100] loss: 0.162\n",
      "[18,   150] loss: 0.160\n",
      "[18,   200] loss: 0.159\n",
      "[18,   250] loss: 0.152\n",
      "[18,   300] loss: 0.214\n",
      "[18,   350] loss: 0.207\n",
      "[18,   400] loss: 0.206\n",
      "[18,   450] loss: 0.183\n",
      "[18,   500] loss: 0.228\n",
      "[18,   550] loss: 0.235\n",
      "[18,   600] loss: 0.237\n",
      "[18,   650] loss: 0.296\n",
      "[18,   700] loss: 0.234\n",
      "Starting epoch 19\n",
      "[19,    50] loss: 0.197\n",
      "[19,   100] loss: 0.171\n",
      "[19,   150] loss: 0.154\n",
      "[19,   200] loss: 0.136\n",
      "[19,   250] loss: 0.144\n",
      "[19,   300] loss: 0.161\n",
      "[19,   350] loss: 0.200\n",
      "[19,   400] loss: 0.190\n",
      "[19,   450] loss: 0.218\n",
      "[19,   500] loss: 0.216\n",
      "[19,   550] loss: 0.252\n",
      "[19,   600] loss: 0.235\n",
      "[19,   650] loss: 0.198\n",
      "[19,   700] loss: 0.222\n",
      "Starting epoch 20\n",
      "[20,    50] loss: 0.215\n",
      "[20,   100] loss: 0.179\n",
      "[20,   150] loss: 0.149\n",
      "[20,   200] loss: 0.154\n",
      "[20,   250] loss: 0.143\n",
      "[20,   300] loss: 0.150\n",
      "[20,   350] loss: 0.158\n",
      "[20,   400] loss: 0.143\n",
      "[20,   450] loss: 0.147\n",
      "[20,   500] loss: 0.135\n",
      "[20,   550] loss: 0.164\n",
      "[20,   600] loss: 0.166\n",
      "[20,   650] loss: 0.156\n",
      "[20,   700] loss: 0.252\n",
      "Validation f1 score: 0.881333214189974\n",
      "Starting epoch 21\n",
      "[21,    50] loss: 0.179\n",
      "[21,   100] loss: 0.124\n",
      "[21,   150] loss: 0.137\n",
      "[21,   200] loss: 0.159\n",
      "[21,   250] loss: 0.167\n",
      "[21,   300] loss: 0.148\n",
      "[21,   350] loss: 0.177\n",
      "[21,   400] loss: 0.164\n",
      "[21,   450] loss: 0.159\n",
      "[21,   500] loss: 0.200\n",
      "[21,   550] loss: 0.199\n",
      "[21,   600] loss: 0.197\n",
      "[21,   650] loss: 0.195\n",
      "[21,   700] loss: 0.182\n",
      "Starting epoch 22\n",
      "[22,    50] loss: 0.115\n",
      "[22,   100] loss: 0.136\n",
      "[22,   150] loss: 0.141\n",
      "[22,   200] loss: 0.140\n",
      "[22,   250] loss: 0.138\n",
      "[22,   300] loss: 0.131\n",
      "[22,   350] loss: 0.132\n",
      "[22,   400] loss: 0.143\n",
      "[22,   450] loss: 0.160\n",
      "[22,   500] loss: 0.193\n",
      "[22,   550] loss: 0.190\n",
      "[22,   600] loss: 0.182\n",
      "[22,   650] loss: 0.141\n",
      "[22,   700] loss: 0.160\n",
      "Starting epoch 23\n",
      "[23,    50] loss: 0.131\n",
      "[23,   100] loss: 0.102\n",
      "[23,   150] loss: 0.120\n",
      "[23,   200] loss: 0.120\n",
      "[23,   250] loss: 0.129\n",
      "[23,   300] loss: 0.133\n",
      "[23,   350] loss: 0.177\n",
      "[23,   400] loss: 0.159\n",
      "[23,   450] loss: 0.194\n",
      "[23,   500] loss: 0.181\n",
      "[23,   550] loss: 0.184\n",
      "[23,   600] loss: 0.141\n",
      "[23,   650] loss: 0.146\n",
      "[23,   700] loss: 0.118\n",
      "Starting epoch 24\n",
      "[24,    50] loss: 0.118\n",
      "[24,   100] loss: 0.143\n",
      "[24,   150] loss: 0.130\n",
      "[24,   200] loss: 0.138\n",
      "[24,   250] loss: 0.121\n",
      "[24,   300] loss: 0.124\n",
      "[24,   350] loss: 0.137\n",
      "[24,   400] loss: 0.143\n",
      "[24,   450] loss: 0.169\n",
      "[24,   500] loss: 0.162\n",
      "[24,   550] loss: 0.139\n",
      "[24,   600] loss: 0.162\n",
      "[24,   650] loss: 0.147\n",
      "[24,   700] loss: 0.138\n",
      "Starting epoch 25\n",
      "[25,    50] loss: 0.107\n",
      "[25,   100] loss: 0.091\n",
      "[25,   150] loss: 0.097\n",
      "[25,   200] loss: 0.092\n",
      "[25,   250] loss: 0.126\n",
      "[25,   300] loss: 0.118\n",
      "[25,   350] loss: 0.140\n",
      "[25,   400] loss: 0.143\n",
      "[25,   450] loss: 0.137\n",
      "[25,   500] loss: 0.133\n",
      "[25,   550] loss: 0.181\n",
      "[25,   600] loss: 0.198\n",
      "[25,   650] loss: 0.155\n",
      "[25,   700] loss: 0.145\n",
      "Validation f1 score: 0.8946474845858278\n",
      "Starting epoch 26\n",
      "[26,    50] loss: 0.092\n",
      "[26,   100] loss: 0.119\n",
      "[26,   150] loss: 0.133\n",
      "[26,   200] loss: 0.107\n",
      "[26,   250] loss: 0.129\n",
      "[26,   300] loss: 0.124\n",
      "[26,   350] loss: 0.115\n",
      "[26,   400] loss: 0.119\n",
      "[26,   450] loss: 0.126\n",
      "[26,   500] loss: 0.164\n",
      "[26,   550] loss: 0.134\n",
      "[26,   600] loss: 0.121\n",
      "[26,   650] loss: 0.104\n",
      "[26,   700] loss: 0.186\n",
      "Starting epoch 27\n",
      "[27,    50] loss: 0.119\n",
      "[27,   100] loss: 0.114\n",
      "[27,   150] loss: 0.118\n",
      "[27,   200] loss: 0.093\n",
      "[27,   250] loss: 0.094\n",
      "[27,   300] loss: 0.082\n",
      "[27,   350] loss: 0.083\n",
      "[27,   400] loss: 0.146\n",
      "[27,   450] loss: 0.139\n",
      "[27,   500] loss: 0.147\n",
      "[27,   550] loss: 0.103\n",
      "[27,   600] loss: 0.126\n",
      "[27,   650] loss: 0.108\n",
      "[27,   700] loss: 0.110\n",
      "Starting epoch 28\n",
      "[28,    50] loss: 0.099\n",
      "[28,   100] loss: 0.096\n",
      "[28,   150] loss: 0.094\n",
      "[28,   200] loss: 0.107\n",
      "[28,   250] loss: 0.113\n",
      "[28,   300] loss: 0.132\n",
      "[28,   350] loss: 0.123\n",
      "[28,   400] loss: 0.093\n",
      "[28,   450] loss: 0.165\n",
      "[28,   500] loss: 0.161\n",
      "[28,   550] loss: 0.146\n",
      "[28,   600] loss: 0.137\n",
      "[28,   650] loss: 0.121\n",
      "[28,   700] loss: 0.145\n",
      "Starting epoch 29\n",
      "[29,    50] loss: 0.081\n",
      "[29,   100] loss: 0.089\n",
      "[29,   150] loss: 0.098\n",
      "[29,   200] loss: 0.110\n",
      "[29,   250] loss: 0.096\n",
      "[29,   300] loss: 0.122\n",
      "[29,   350] loss: 0.090\n",
      "[29,   400] loss: 0.134\n",
      "[29,   450] loss: 0.103\n",
      "[29,   500] loss: 0.103\n",
      "[29,   550] loss: 0.139\n",
      "[29,   600] loss: 0.107\n",
      "[29,   650] loss: 0.131\n",
      "[29,   700] loss: 0.117\n",
      "Starting epoch 30\n",
      "[30,    50] loss: 0.105\n",
      "[30,   100] loss: 0.109\n",
      "[30,   150] loss: 0.115\n",
      "[30,   200] loss: 0.101\n",
      "[30,   250] loss: 0.127\n",
      "[30,   300] loss: 0.094\n",
      "[30,   350] loss: 0.094\n",
      "[30,   400] loss: 0.085\n",
      "[30,   450] loss: 0.068\n",
      "[30,   500] loss: 0.111\n",
      "[30,   550] loss: 0.105\n",
      "[30,   600] loss: 0.122\n",
      "[30,   650] loss: 0.118\n",
      "[30,   700] loss: 0.117\n",
      "Validation f1 score: 0.8896434634974533\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#Train it\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    print('Starting epoch', epoch + 1)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data[0].to(device), data[1]['genre'].to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = stn(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 30 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 30))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    if epoch % 5 == 4:\n",
    "        validate(stn, 'genre')\n",
    "        stn.train()\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = '../models/DCNN_{}_{}'.format(dataset_name, 'genre')\n",
    "torch.save(stn, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): STN(\n",
       "    (layer1): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (1): ELU(alpha=1.0)\n",
       "      (2): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0)\n",
       "      (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ELU(alpha=1.0)\n",
       "      (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0)\n",
       "      (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layer5): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ELU(alpha=1.0)\n",
       "      (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer6): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ELU(alpha=1.0)\n",
       "    )\n",
       "    (layer7): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0)\n",
       "    )\n",
       "    (global_avg_pool): Sequential(\n",
       "      (0): GlobalAvgPool(\n",
       "        (layer): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "          (1): Flatten()\n",
       "        )\n",
       "      )\n",
       "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (densefc): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0)\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (output_layer): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file = '../models/DCNN_{}_{}'.format(dataset_name, 'genre')\n",
    "model = torch.load(model_file)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 score: 0.8896434634974533\n"
     ]
    }
   ],
   "source": [
    "validate(model, 'genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
